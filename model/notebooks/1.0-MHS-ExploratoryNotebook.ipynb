{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Notebook\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook has been made by Martin Sejas*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import typing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading and Splitting Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240122, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air_India</td>\n",
       "      <td>AI-804</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>one</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Business</td>\n",
       "      <td>16.00</td>\n",
       "      <td>11</td>\n",
       "      <td>54684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air_India</td>\n",
       "      <td>AI-503</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Evening</td>\n",
       "      <td>one</td>\n",
       "      <td>Night</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Economy</td>\n",
       "      <td>6.25</td>\n",
       "      <td>12</td>\n",
       "      <td>13054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO_FIRST</td>\n",
       "      <td>G8-426</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Night</td>\n",
       "      <td>one</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Economy</td>\n",
       "      <td>10.33</td>\n",
       "      <td>34</td>\n",
       "      <td>6256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indigo</td>\n",
       "      <td>6E-534</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Evening</td>\n",
       "      <td>one</td>\n",
       "      <td>Night</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>5.33</td>\n",
       "      <td>21</td>\n",
       "      <td>5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-863</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Morning</td>\n",
       "      <td>two_or_more</td>\n",
       "      <td>Night</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>11.17</td>\n",
       "      <td>45</td>\n",
       "      <td>8130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     airline  flight source_city departure_time        stops arrival_time  \\\n",
       "0  Air_India  AI-804   Bangalore  Early_Morning          one        Night   \n",
       "1  Air_India  AI-503   Bangalore        Evening          one        Night   \n",
       "2   GO_FIRST  G8-426   Hyderabad          Night          one      Morning   \n",
       "3     Indigo  6E-534     Kolkata        Evening          one        Night   \n",
       "4    Vistara  UK-863      Mumbai        Morning  two_or_more        Night   \n",
       "\n",
       "  destination_city     class  duration  days_left  price  \n",
       "0           Mumbai  Business     16.00         11  54684  \n",
       "1        Hyderabad   Economy      6.25         12  13054  \n",
       "2        Bangalore   Economy     10.33         34   6256  \n",
       "3          Chennai   Economy      5.33         21   5280  \n",
       "4          Chennai   Economy     11.17         45   8130  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading csv file\n",
    "master = pd.read_csv(\"../raw_data/flight-price-training.csv\")\n",
    "\n",
    "#creating a copy for exploration\n",
    "df = master.copy()\n",
    "\n",
    "#Dropping the first column that is simply the original index of row before partitioning\n",
    "df = df.drop(columns=df.columns[0])\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that we have 10 features and 1 label ('price'), we can also see a lot of our features are categorical, and encoded in an inconvenient manner, for example, the column ('stops') is in string format instead of number, we will have to see the different classes contained in this column to decide if we convert it to a number or keep it as a categorical variable. Similar treatment will be needed for other variables, such as 'departure_time' decide how we treat them. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check for any nan's, and see general info of our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240122 entries, 0 to 240121\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   airline           240122 non-null  object \n",
      " 1   flight            240122 non-null  object \n",
      " 2   source_city       240122 non-null  object \n",
      " 3   departure_time    240122 non-null  object \n",
      " 4   stops             240122 non-null  object \n",
      " 5   arrival_time      240122 non-null  object \n",
      " 6   destination_city  240122 non-null  object \n",
      " 7   class             240122 non-null  object \n",
      " 8   duration          240122 non-null  float64\n",
      " 9   days_left         240122 non-null  int64  \n",
      " 10  price             240122 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 20.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, all of the features + label match the shape of the dataframe, 240122, meaning that there are no NaN values so no imputation technique would be needed. We can proceed to check the different classes in our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline: Unique values: ['Air_India' 'GO_FIRST' 'Indigo' 'Vistara' 'AirAsia' 'SpiceJet']\n",
      "count: 6\n",
      "\n",
      "flight: Unique values: ['AI-804' 'AI-503' 'G8-426' ... '6E-543' '6E-865' 'I5-1427']\n",
      "count: 1556\n",
      "\n",
      "source_city: Unique values: ['Bangalore' 'Hyderabad' 'Kolkata' 'Mumbai' 'Delhi' 'Chennai']\n",
      "count: 6\n",
      "\n",
      "departure_time: Unique values: ['Early_Morning' 'Evening' 'Night' 'Morning' 'Afternoon' 'Late_Night']\n",
      "count: 6\n",
      "\n",
      "stops: Unique values: ['one' 'two_or_more' 'zero']\n",
      "count: 3\n",
      "\n",
      "arrival_time: Unique values: ['Night' 'Morning' 'Afternoon' 'Early_Morning' 'Evening' 'Late_Night']\n",
      "count: 6\n",
      "\n",
      "destination_city: Unique values: ['Mumbai' 'Hyderabad' 'Bangalore' 'Chennai' 'Delhi' 'Kolkata']\n",
      "count: 6\n",
      "\n",
      "class: Unique values: ['Business' 'Economy']\n",
      "count: 2\n",
      "\n",
      "duration: Unique values: [16.    6.25 10.33  5.33 11.17  9.75  2.17 10.5   8.83 15.17  8.75  2.\n",
      " 16.08  2.92  3.58  6.75  9.5   8.08 22.5   4.42 14.58 11.25 11.75 21.5\n",
      "  5.83 11.    9.25  6.17  8.   12.25 35.75  6.92  6.83 22.58  9.83  3.92\n",
      "  8.25 18.17 16.5  12.42 11.92 11.08 30.25  4.92 24.5  15.58 13.08  7.67\n",
      " 11.67 10.67  1.25 22.25  6.58  2.25 22.33 25.83  2.83 13.83  6.33  9.58\n",
      "  5.08 14.17  7.58  7.    8.17 10.42 13.25 18.58 24.92 22.17 16.17 17.58\n",
      "  9.17 14.5   5.67  8.33 14.92  2.33  7.08 18.83  7.33 23.42  8.58 25.17\n",
      "  2.5   2.58 14.42  2.75 31.25  9.    8.92 20.42 12.58  5.58 12.   19.42\n",
      "  8.67 12.83 24.17 23.17 14.   24.58 16.67  8.42  4.   13.5  27.25 21.33\n",
      " 19.   11.83 14.83 12.08  7.17 17.92 10.08  1.17  3.75  4.75  2.08  7.25\n",
      " 13.67 12.75  5.42 33.67 15.    5.5  24.83 13.   15.83  9.92 23.25 16.42\n",
      " 30.58 10.92 17.42 18.67 13.58 12.67  5.    9.33  2.67  1.83 15.42 10.25\n",
      " 26.33  8.5  25.67 28.   12.5  10.58  9.08 26.58 20.33  2.42 14.67 15.08\n",
      " 16.83 11.58 22.92 13.33 27.17  1.5  25.75  4.5   6.5  23.67 25.   22.83\n",
      " 13.75 16.58 15.75 21.58 24.    5.25 11.33 14.75 14.33 23.5  28.83 15.5\n",
      " 21.25 16.75 12.92 19.25  6.42 10.    5.75 12.33  1.33  1.   25.08 24.33\n",
      "  6.08 23.58  7.5  15.92 23.33 10.17 22.42 10.83 11.5  15.25  1.75 27.67\n",
      " 14.25 20.83 27.5  26.08 16.33 17.5  35.08 13.42 24.08  4.33 18.42  7.42\n",
      " 35.42 24.67 13.92 16.92 23.08 24.75  4.83 16.25  4.25  6.67 17.   25.92\n",
      "  5.17  1.67 19.58  9.67 25.42 19.75 17.67 17.33 26.5   3.42 11.42 23.83\n",
      " 18.92 14.08 25.25  1.58 18.   25.58  6.98 24.25 13.17  6.   21.   23.92\n",
      "  7.83 12.17 20.58 26.17  5.92 26.75 20.5   3.5  21.17 29.5  17.17 27.83\n",
      "  4.17 21.83  4.08 15.67 18.75 23.    7.75 19.83 29.75 26.67  1.92 29.17\n",
      " 21.67 19.67 20.67 22.   22.75 28.42 26.42  4.67 18.08 21.08 31.58  7.92\n",
      " 20.92 27.33 21.42 25.33  1.08 26.   34.83 26.83  4.58  1.42 27.08 17.25\n",
      "  3.   19.92 28.58  3.33 27.42 29.08 20.08 17.83 21.75 30.08 27.92 19.17\n",
      "  9.42 17.08 32.17 37.   10.75 18.25 23.75 19.33 18.33 22.08 19.08 17.75\n",
      " 30.67 25.5  19.5  29.67 15.33 20.25 37.92  3.08 26.92 28.25 28.33 20.17\n",
      " 24.42 20.75  0.83  3.17 26.25 20.   27.   22.67 27.75 31.5  34.33 35.58\n",
      " 33.75 28.08 21.92 27.58 18.5  33.5  35.5  30.33 32.   28.5  31.08 37.75\n",
      " 33.58 33.    3.67 31.17  3.83  6.07 31.75 33.92 29.83  3.25 32.58 33.33\n",
      " 30.75 28.92 38.58 33.83 40.42 30.5  28.17 31.33 42.   29.92 29.58 31.42\n",
      " 29.33 32.75 33.42 37.33  0.92 36.   13.4  31.67 34.67 37.83 32.42 38.33\n",
      " 28.75 38.5  32.33 31.83 28.67 34.08 29.42 36.08 34.5  36.17 34.   33.17\n",
      " 34.58 40.92 39.67 29.   35.33 30.   32.08 34.25 31.   32.67 33.25 36.83\n",
      " 40.67 29.25 32.5  35.17 39.92 34.92 37.5  35.25 35.92 38.67 31.92 37.58\n",
      " 32.92 30.42 39.   36.42 32.25 30.17 40.5  30.83 39.42 35.67 37.67 36.75\n",
      " 37.42 33.08 41.5  32.83 38.83 39.08 39.83 36.92 34.42 34.75 38.75 36.5\n",
      " 35.83 45.83 36.25 36.58 34.17 37.08 41.58 39.75 37.17 47.75 41.83 41.08\n",
      " 30.92 40.   37.25 44.5 ]\n",
      "count: 472\n",
      "\n",
      "days_left: Unique values: [11 12 34 21 45 38 42  1 35 39 10 32 28 46 23 17  6 25 18 13 29 36 14  5\n",
      " 44 33 49 24 40 19 48  7 31 47 43 22 41 27  8 30  4 20  3  2  9 26 15 16\n",
      " 37]\n",
      "count: 49\n",
      "\n",
      "price: Unique values: [54684 13054  6256 ...  8071  9823 25800]\n",
      "count: 11387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"{col}: Unique values: {df[col].unique()}\")\n",
    "    print(f\"count: {len(df[col].unique())}\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we will have a feature implosion with the flights, as there are 1556 unique values, additionally the actual code of the flight should not affect the price of the model. Considering I don't have many features, I will make two models, one with it, and one without."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will split the dataset into 80% training data, 10% validation, and 10% testing data. I will stratify the 'class' of the ticket (Business/Economy) to make sure my data is well balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#separating features from label\n",
    "Y = df['price']\n",
    "X = df.drop(columns=['price'])\n",
    "\n",
    "#Setting 80% to the training set\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X, Y, test_size=0.2, stratify=X['class'], random_state=42)\n",
    "\n",
    "#Setting 10% to the validation set and 10% to the test set\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rest, y_rest, test_size=0.5,stratify=X_rest['class'], random_state=42 )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, the 'stops' feature needs to be ordinally encoded. The functions below take care of this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will read a string with 'one' ,'two_or_more' or 'zero' and return the appropriate integer\n",
    "def encode_stops(s:str)-> int:\n",
    "    if (s == 'one'):\n",
    "        return 1\n",
    "    elif(s == 'zero'):\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def process_stops_column(df: pd.DataFrame)->pd.DataFrame:\n",
    "    df['stops'] = df['stops'].apply(encode_stops)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air_India</td>\n",
       "      <td>AI-804</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>1</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Business</td>\n",
       "      <td>16.00</td>\n",
       "      <td>11</td>\n",
       "      <td>54684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air_India</td>\n",
       "      <td>AI-503</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Evening</td>\n",
       "      <td>1</td>\n",
       "      <td>Night</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Economy</td>\n",
       "      <td>6.25</td>\n",
       "      <td>12</td>\n",
       "      <td>13054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO_FIRST</td>\n",
       "      <td>G8-426</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Night</td>\n",
       "      <td>1</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Economy</td>\n",
       "      <td>10.33</td>\n",
       "      <td>34</td>\n",
       "      <td>6256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indigo</td>\n",
       "      <td>6E-534</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Evening</td>\n",
       "      <td>1</td>\n",
       "      <td>Night</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>5.33</td>\n",
       "      <td>21</td>\n",
       "      <td>5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-863</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Morning</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>11.17</td>\n",
       "      <td>45</td>\n",
       "      <td>8130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     airline  flight source_city departure_time  stops arrival_time  \\\n",
       "0  Air_India  AI-804   Bangalore  Early_Morning      1        Night   \n",
       "1  Air_India  AI-503   Bangalore        Evening      1        Night   \n",
       "2   GO_FIRST  G8-426   Hyderabad          Night      1      Morning   \n",
       "3     Indigo  6E-534     Kolkata        Evening      1        Night   \n",
       "4    Vistara  UK-863      Mumbai        Morning      2        Night   \n",
       "\n",
       "  destination_city     class  duration  days_left  price  \n",
       "0           Mumbai  Business     16.00         11  54684  \n",
       "1        Hyderabad   Economy      6.25         12  13054  \n",
       "2        Bangalore   Economy     10.33         34   6256  \n",
       "3          Chennai   Economy      5.33         21   5280  \n",
       "4          Chennai   Economy     11.17         45   8130  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing our function \n",
    "\n",
    "df_test = df.copy()\n",
    "\n",
    "df_test_processed = process_stops_column(df=df_test)\n",
    "\n",
    "df_test_processed.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence now we can implement our main pre-processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\FlightPricePredictionEnv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:202: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\FlightPricePredictionEnv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:202: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import (StandardScaler, OneHotEncoder)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Here I want to make two separate column transformers, one with the 'flight' column, and one without. \n",
    "#Hence I will here make my distinctions\n",
    "\n",
    "X_train_no_flight = X_train.drop(columns=['flight'])\n",
    "X_valid_no_flight = X_valid.drop(columns=['flight'])\n",
    "X_test_no_flight = X_test.drop(columns=['flight'])\n",
    "\n",
    "#dropping the 'stops' feature because this will be handled differently\n",
    "#Applying initial custom transformation\n",
    "X_train_p_stops = process_stops_column(X_train)\n",
    "X_valid_p_stops = process_stops_column(X_valid)\n",
    "X_test_p_stops = process_stops_column(X_test)\n",
    "\n",
    "X_train_no_flight_p_stops = process_stops_column(X_train_no_flight)\n",
    "X_valid_no_flight_p_stops = process_stops_column(X_valid_no_flight)\n",
    "X_test_no_flight_p_stops = process_stops_column(X_test_no_flight)\n",
    "\n",
    "\n",
    "#getting the right categorical columns \n",
    "full_categorical_columns = (X_train_p_stops.select_dtypes(include=['object'])).columns\n",
    "partial_categorical_columns = (X_train_no_flight_p_stops.select_dtypes(include=['object'])).columns\n",
    "\n",
    "#Extracting numerical columns\n",
    "numerical_columns = list(set(X_train_p_stops.columns) - set(full_categorical_columns))\n",
    "\n",
    "#transformer with 'flight' column included\n",
    "ct_main = ColumnTransformer(\n",
    "                [(\"ohe\", OneHotEncoder(drop='if_binary', sparse_output=False, handle_unknown='ignore'), full_categorical_columns),\n",
    "                 (\"std\", StandardScaler(), numerical_columns)\n",
    "                ])\n",
    "\n",
    "#transformer without 'flight' column included\n",
    "ct_secondary = ColumnTransformer(\n",
    "                [(\"ohe\", OneHotEncoder(drop='if_binary', sparse_output=False, handle_unknown='ignore'), partial_categorical_columns),\n",
    "                 (\"std\", StandardScaler(), numerical_columns)\n",
    "                ])\n",
    "\n",
    "#Applying main pre-processing\n",
    "ct_main.fit(X_train_p_stops)\n",
    "X_train_p = ct_main.transform(X_train_p_stops)\n",
    "X_valid_p = ct_main.transform(X_valid_p_stops)\n",
    "X_test_p = ct_main.transform(X_test_p_stops)\n",
    "\n",
    "#Applying secondary pre-processing\n",
    "ct_secondary.fit(X_train_no_flight_p_stops)\n",
    "X_train_no_flight_p = ct_secondary.transform(X_train_no_flight_p_stops)\n",
    "X_valid_no_flight_p = ct_secondary.transform(X_valid_no_flight_p_stops)\n",
    "X_test_no_flight_p = ct_secondary.transform(X_test_no_flight_p_stops)\n",
    "\n",
    "#Label is numerical, so we need to also normalize it\n",
    "y_std = StandardScaler()\n",
    "\n",
    "#Reshaping y to pre-process\n",
    "y_train = (y_train.to_numpy()).reshape(-1,1)\n",
    "y_valid = (y_valid.to_numpy()).reshape(-1,1)\n",
    "y_test = (y_test.to_numpy()).reshape(-1,1)\n",
    "\n",
    "#Pre-processing the label\n",
    "y_std.fit(y_train)\n",
    "y_train_p = y_std.transform(y_train)\n",
    "y_valid_p = y_std.transform(y_valid)\n",
    "y_test_p = y_std.transform(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training and Evaluating Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the very first model we will just use a simple Linear Regression (Gradient Descent) and our main initial goal here, is to see if there are any impactful performance differences in having the flight code or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3681745022692510.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#with flight column\n",
    "main_model = LinearRegression()\n",
    "\n",
    "#fitting the main model\n",
    "main_model.fit(X_train_p,y=y_train_p)\n",
    "\n",
    "main_model.score(X=X_test_p, y=y_test_p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9005264698784824"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Without flight column\n",
    "model_no_flights = LinearRegression()\n",
    "\n",
    "model_no_flights.fit(X=X_train_no_flight_p, y=y_train_p)\n",
    "\n",
    "model_no_flights.score(X=X_test_no_flight_p, y=y_test_p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'score' method called in each method calculates how well the predictions correlate with the validation set. It's called the coefficient of determination, where the best 'score' is 1.0. We can see here that the model that included the flight-codes is garbage, while the model that excludes the 'flights' column has a very good score of 0.9.\n",
    "\n",
    "Having that in mind we will explore future models excluding the 'flights' column. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the mean squared error (for no_flights model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE valid: 0.09688468443307602\n",
      "MSE test: 0.10007568539728301\n",
      "Average MSE: 0.09848018491517951\n",
      "Mean Absolute Percentage Error: 36.7803999879977%\n"
     ]
    }
   ],
   "source": [
    "#checking the error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "y_preds = model_no_flights.predict(X_valid_no_flight_p)\n",
    "mse_valid = mean_squared_error(y_true=y_valid_p,y_pred=y_preds )\n",
    "print(f\"MSE valid: {mse_valid}\")\n",
    "\n",
    "y_preds = model_no_flights.predict(X_test_no_flight_p)\n",
    "mse_test = mean_squared_error(y_true=y_test_p,y_pred=y_preds )\n",
    "print(f\"MSE test: {mse_test}\")\n",
    "\n",
    "print(f\"Average MSE: {sum([mse_valid,mse_test])/2}\")\n",
    "\n",
    "masp = mean_absolute_percentage_error(y_true = y_test, y_pred=(y_std.inverse_transform(y_preds)))\n",
    "print(f\"Mean Absolute Percentage Error: {masp*100}%\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the mean absolute percentage error to have an idea of the performance of our models.\n",
    "\n",
    "**NOTE: The MSE's have been calculated on the normalized predictions, and validation sets.**\n",
    "\n",
    "**NOTE: The masp has been calculated on values of the actual dataset.**\n",
    "\n",
    "Note that this is done on the actual flight prices in (indian rupees)\n",
    "\n",
    "We can see that our Mean Absolute Percentage Error (36%) seems high. However we must consider we only have around 7 features. If we had more features, for example date, where price hikes due to holidays could be factored in, we would have a more performing model.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the model without the flights column is superior, and converges much faster. We will attempt to achieve a better performance by applying regularization on our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9005309703283476\n",
      "1e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "#generating a range of alphas \n",
    "alphas = np.logspace(-5,5,100)\n",
    "\n",
    "best_alpha = alphas[0]\n",
    "best_score = -1000000\n",
    "\n",
    "for alpha in alphas:\n",
    "    \n",
    "    model_ridge = Ridge(alpha=alpha)\n",
    "\n",
    "    model_ridge.fit(X_train_no_flight_p, y_train_p)\n",
    "    score = model_ridge.score(X=X_test_no_flight_p, y=y_test_p)\n",
    "    \n",
    "    if(score > best_score):\n",
    "        best_score = score\n",
    "        best_alpha = alpha\n",
    "\n",
    "\n",
    "print(best_score)\n",
    "print(best_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE valid: 0.4950850965963323\n",
      "MSE test: 0.5041028720954136\n",
      "Average MSE: 0.499593984345873\n",
      "Mean Absolute Percentage Error: 150.95730624697092%\n"
     ]
    }
   ],
   "source": [
    "#checking the error\n",
    "\n",
    "y_preds = model_ridge.predict(X_valid_no_flight_p)\n",
    "mse_valid = mean_squared_error(y_true=y_valid_p,y_pred=y_preds )\n",
    "print(f\"MSE valid: {mse_valid}\")\n",
    "\n",
    "y_preds = model_ridge.predict(X_test_no_flight_p)\n",
    "mse_test = mean_squared_error(y_true=y_test_p,y_pred=y_preds )\n",
    "print(f\"MSE test: {mse_test}\")\n",
    "\n",
    "print(f\"Average MSE: {sum([mse_valid,mse_test])/2}\")\n",
    "masp = mean_absolute_percentage_error(y_true = y_test, y_pred=y_std.inverse_transform(y_preds))\n",
    "print(f\"Mean Absolute Percentage Error: {masp*100}%\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that implement Ridge regularization did show improvement to our model, as we have a lower Mean Squared Error(MSE). \n",
    "\n",
    "Having that in mind we will check if an elastic net with cross validation would improve our model further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha = 0.0008689976557719299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9004640723995209"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "\n",
    "model_en = ElasticNetCV(random_state=42)\n",
    "\n",
    "#fitting the main model\n",
    "model_en.fit(X=X_train_no_flight_p, y=y_train_p.ravel())\n",
    "\n",
    "print(f\"best alpha = {model_en.alpha_}\")\n",
    "\n",
    "model_en.score(X=X_test_no_flight_p, y=y_test_p)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating MSE for our ElasticNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE valid: 0.09690949926382428\n",
      "MSE test: 0.10013846059452904\n",
      "Average MSE: 0.09852397992917666\n",
      "Mean Absolute Percentage Error: 36.30954982794132%\n"
     ]
    }
   ],
   "source": [
    "y_preds = model_en.predict(X_valid_no_flight_p)\n",
    "mse_valid = mean_squared_error(y_true=y_valid_p,y_pred=y_preds )\n",
    "print(f\"MSE valid: {mse_valid}\")\n",
    "\n",
    "y_preds = model_en.predict(X_test_no_flight_p)\n",
    "mse_test = mean_squared_error(y_true=y_test_p,y_pred=y_preds )\n",
    "print(f\"MSE test: {mse_test}\")\n",
    "\n",
    "print(f\"Average MSE: {sum([mse_valid,mse_test])/2}\")\n",
    "\n",
    "masp = mean_absolute_percentage_error(y_true = y_test, y_pred=y_std.inverse_transform(y_preds.reshape(-1,1)))\n",
    "print(f\"Mean Absolute Percentage Error: {masp*100}%\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the ElasticNet Model which implements L1 and L2 regularization + GridSearch model greatly outperforms the standard LinearRegressor and RidgeRegressor. \n",
    "\n",
    "With an average MSE of 0.0985 the results are excellent.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here we will try to use a Polynomial Transformation to see if we can get a better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\FlightPricePredictionEnv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.841e+01, tolerance: 1.921e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha = 0.0008689976557719299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9310980323760176"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "poly.fit(X_train_no_flight_p)\n",
    "\n",
    "model_en_poly = ElasticNetCV(random_state=42)\n",
    "\n",
    "\n",
    "#fitting the main model\n",
    "model_en_poly.fit(X=poly.transform(X_train_no_flight_p), y=y_train_p.ravel())\n",
    "\n",
    "print(f\"best alpha = {model_en_poly.alpha_}\")\n",
    "\n",
    "model_en_poly.score(X=poly.transform(X_test_no_flight_p), y=y_test_p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE valid: 0.06695864048268976\n",
      "MSE test: 0.06931906032457026\n",
      "Average MSE: 0.06813885040363002\n",
      "Mean Absolute Percentage Error: 33.26128055926997%\n"
     ]
    }
   ],
   "source": [
    "y_preds = model_en_poly.predict(poly.transform(X_valid_no_flight_p))\n",
    "mse_valid = mean_squared_error(y_true=y_valid_p,y_pred=y_preds )\n",
    "print(f\"MSE valid: {mse_valid}\")\n",
    "\n",
    "y_preds = model_en_poly.predict(poly.transform(X_test_no_flight_p))\n",
    "mse_test = mean_squared_error(y_true=y_test_p,y_pred=y_preds )\n",
    "print(f\"MSE test: {mse_test}\")\n",
    "\n",
    "print(f\"Average MSE: {sum([mse_valid,mse_test])/2}\")\n",
    "\n",
    "masp = mean_absolute_percentage_error(y_true = y_test, y_pred=y_std.inverse_transform(y_preds.reshape(-1,1)))\n",
    "print(f\"Mean Absolute Percentage Error: {masp*100}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Conclusion and Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlightPricePredictionEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
